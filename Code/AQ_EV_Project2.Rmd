---
title: "Longitudinal"
author: "Kajal Gupta"
date: "2025-04-17"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Step 1: Clean and Prepare EV Data (2014–2024)

```{r, warning=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(stringr)
library(lubridate)

# Load EV station dataset
ev_data <- read_csv("EV_CS_NYC.csv")

# Clean and extract installation year, assign NYC boroughs
ev_data_clean <- ev_data %>%
  mutate(
    Open_Date = mdy(`Open Date`),
    Open_Year = year(Open_Date),
    City = str_to_upper(str_trim(City)),
    BOROUGH = case_when(
      City %in% c("NEW YORK", "MANHATTAN") ~ "MANHATTAN",
      City == "BROOKLYN" ~ "BROOKLYN",
      City == "BRONX" ~ "BRONX",
      City == "QUEENS" ~ "QUEENS",
      City == "STATEN ISLAND" ~ "STATEN ISLAND",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(Open_Year >= 2014 & Open_Year <= 2024, !is.na(BOROUGH))

```






Step 2: Aggregate EV Data by BOROUGH + YEAR and Keep Relevant Covariates
```{r, warning=FALSE, message=FALSE}
ev_summary <- ev_data_clean %>%
  group_by(BOROUGH, Open_Year) %>%
  summarise(
    Stations = n(),
    Total_Level2 = sum(`EV Level2 EVSE Num`, na.rm = TRUE),
    Total_DCFC = sum(`EV DC Fast Count`, na.rm = TRUE),
    Public_Pct = mean(`Groups With Access Code` == "Public", na.rm = TRUE),
    Avg_Level2_Per_Station = mean(`EV Level2 EVSE Num`, na.rm = TRUE),
    Avg_DCFC_Per_Station = mean(`EV DC Fast Count`, na.rm = TRUE)
  ) %>%
  rename(Year = Open_Year) %>%
  arrange(BOROUGH, Year) %>%
  group_by(BOROUGH) %>%
  mutate(
    EV_Growth_Rate = (Stations - lag(Stations)) / lag(Stations)
  ) %>%
  ungroup()
```












Step 3: Clean and Filter Air Quality Data
```{r, warning=FALSE, message=FALSE}
air_quality <- read_csv("Air_Quality.csv") %>%
  mutate(
    Start_Date = mdy(Start_Date),
    Year = year(Start_Date),
    `Geo Place Name` = str_trim(`Geo Place Name`),
    Region = str_to_upper(`Geo Place Name`)
  )

# Map Geo.Place.Name to Boroughs
borough_keywords <- list(
  "BRONX" = c("BRONX", "FORDHAM", "MORRISANIA", "KINGSBRIDGE"),
  "BROOKLYN" = c("BROOKLYN", "BEDFORD", "EAST NEW YORK", "BUSHWICK"),
  "MANHATTAN" = c("MANHATTAN", "HARLEM", "CHELSEA", "GRAMERCY", "TRIBECA"),
  "QUEENS" = c("QUEENS", "JAMAICA", "FLUSHING", "ASTORIA"),
  "STATEN ISLAND" = c("STATEN ISLAND", "TOTTENVILLE", "ST. GEORGE")
)

get_borough <- function(region) {
  if (is.na(region)) return(NA)
  for (b in names(borough_keywords)) {
    if (any(str_detect(region, borough_keywords[[b]]))) return(b)
  }
  return(NA)
}

air_quality$BOROUGH <- sapply(air_quality$Region, get_borough)

air_quality <- air_quality %>%
  filter(!is.na(BOROUGH), Year >= 2014 & Year <= 2024)

```











Step 4: Merge EV + Air Quality Data by BOROUGH + YEAR

```{r, warning=FALSE, message=FALSE}
merged_data <- air_quality %>%
  left_join(ev_summary, by = c("BOROUGH", "Year"))
colnames(merged_data)
```









Step 5: Add Derived Covariates
```{r, warning=FALSE, message=FALSE}
merged_data <- merged_data %>%
  rename(Data_Value = `Data Value`)

# Define borough areas (in square miles)
borough_area_mi2 <- c(
  "BRONX" = 42,
  "BROOKLYN" = 69,
  "MANHATTAN" = 22,
  "QUEENS" = 109,
  "STATEN ISLAND" = 58
)

merged_data <- merged_data %>%
  mutate(
    EV_Station_Density = Stations / borough_area_mi2[BOROUGH],
    Time_Since_EV_Adoption = Year - 2014,
    Level2_to_DCFC_Ratio = ifelse(Total_DCFC > 0, Total_Level2 / Total_DCFC, NA),
    Chargers_Per_Station = (Total_Level2 + Total_DCFC) / Stations
  ) %>%
  group_by(BOROUGH, Name) %>%
  arrange(Year) %>%
  mutate(
    Pollutant_Change = Data_Value - lag(Data_Value),
    Pollutant_Rate_Change = (Data_Value - lag(Data_Value)) / lag(Data_Value)
  ) %>%
  ungroup()

```





Step 6: Final Variable Selection and Save
```{r, warning=FALSE, message=FALSE}
final_data <- merged_data %>%
  select(
    BOROUGH, Year, `Geo Place Name`, Name, Measure, `Measure Info`, Data_Value,
    Pollutant_Change, Pollutant_Rate_Change,
    Stations, Total_Level2, Total_DCFC,
    Public_Pct, Avg_Level2_Per_Station, Avg_DCFC_Per_Station,
    EV_Growth_Rate, EV_Station_Density, Chargers_Per_Station,
    Level2_to_DCFC_Ratio, Time_Since_EV_Adoption
  )

write_csv(final_data, "Final_NYC_Longitudinal_EV_AQ_2014_2024.csv")
print("✅ Final dataset with all derived covariates saved!")

```



```{r, warning=FALSE, message=FALSE}
analysis_data <- read.csv("Final_NYC_Longitudinal_EV_AQ_2014_2024.csv")
colnames(analysis_data)
# Check NAs column-wise
colSums(is.na(final_data))
str(analysis_data)
```




```{r, warning=FALSE, message=FALSE}
# Step 1: Keep borough-years where EV data exists
analysis_data_filtered <- analysis_data %>%
  filter(Year >= 2014, !is.na(Stations))  # Drop 2020 + boroughs with no EV stations that year

# Step 2 (optional): check how many regions per borough-year remain
table(analysis_data_filtered$BOROUGH, analysis_data_filtered$Year)

# Step 3 (optional): Save filtered data
write.csv(analysis_data_filtered, "Model_Ready_EV_AQ_Data.csv", row.names = FALSE)

```




```{r, warning=FALSE, message=FALSE}
model_data <- read.csv("Model_Ready_EV_AQ_Data.csv")
colnames(model_data)
# Check NAs column-wise
colSums(is.na(model_data))
str(model_data)
nrow(model_data)
model_data <- model_data %>%
  select(-Level2_to_DCFC_Ratio, -Avg_DCFC_Per_Station)
colnames(model_data)
# Check NAs column-wise
colSums(is.na(model_data))
nrow(model_data)
str(model_data)
write.csv(model_data, "Clean_Model_Ready_EV_AQ_Data.csv", row.names = FALSE)
print("✅ Clean modeling dataset saved as 'Clean_Model_Ready_EV_AQ_Data.csv'")

```

### ANALYSIS 


Load Dataset
```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(psych)
library(corrplot)
library(plm)
library(tidyr)
library(ggthemes)
library(readr)

# Load cleaned data
model_data <- read.csv("Clean_Model_Ready_EV_AQ_Data.csv")
colSums(is.na(model_data))
nrow(model_data)
```



\newpage
Step 1: Descriptive Statistics
```{r, warning=FALSE, message=FALSE}
# Summary statistics for all numeric variables
desc_stats <- model_data %>%
  select(where(is.numeric)) %>%
  psych::describe()

print(desc_stats)

```


\newpage
1. Temporal Alignment (Granger Causality & Lagged Variables)
```{r}
# Create lagged EV variables
model_data <- model_data %>%
  group_by(BOROUGH, Geo.Place.Name, Name) %>%
  arrange(Year) %>%
  mutate(
    EV_Density_Lag1 = lag(EV_Station_Density, 1),
    EV_Density_Lag2 = lag(EV_Station_Density, 2),
    Pollution_Lead1 = lead(Data_Value, 1)
  ) %>%
  ungroup()

# Granger Causality Test (package vars would be better but keeping it simple)
granger_test <- lm(Data_Value ~ EV_Density_Lag1 + EV_Density_Lag2 + 
                   lag(Data_Value,1) + lag(Data_Value,2) + 
                   factor(BOROUGH) + factor(Year), 
                 data = model_data)
summary(granger_test) # Check significance of lagged EV terms

# Event study plot for 2018 policy change
event_study <- model_data %>%
  mutate(Time_to_Treat = Year - 2018) %>%
  filter(Time_to_Treat >= -3 & Time_to_Treat <= 3) # 3 years before/after

ggplot(event_study, aes(x = Time_to_Treat, y = Data_Value, color = BOROUGH)) +
  stat_summary(fun = mean, geom = "line") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(title = "Event Study: Air Quality Around 2018 EV Policy Change",
       x = "Years Relative to Policy", y = "Pollution Level")
```


\newpage
Step 2: EDA (Exploratory Data Analysis)
```{r, warning=FALSE, message=FALSE}
# Pollutant frequency
table(model_data$Name)

# Observation count per borough/year
table(model_data$BOROUGH, model_data$Year)

# Mean pollution by borough
model_data %>%
  group_by(BOROUGH) %>%
  summarise(
    Mean_Pollution = mean(Data_Value),
    SD = sd(Data_Value),
    Min = min(Data_Value),
    Max = max(Data_Value),
    n = n()
  )

```




\newpage
Step 3: Visualizations

3.1 Profile Plot (Pollution over Time by Borough)
```{r, warning=FALSE, message=FALSE}
ggplot(model_data, aes(x = Year, y = Data_Value, group = BOROUGH, color = BOROUGH)) +
  stat_summary(fun = mean, geom = "line", size = 1.2) +
  stat_summary(fun = mean, geom = "point", size = 2) +
  labs(title = "Profile Plot: Air Pollution Trends by Borough (2014–2024)",
       x = "Year", y = "Mean Pollution Level") +
  theme_minimal()

```




\newpage
3.2: Distribution of Pollution Levels
```{r, warning=FALSE, message=FALSE}
ggplot(model_data, aes(x = Data_Value, fill = BOROUGH)) +
  geom_histogram(alpha = 0.6, bins = 30, position = "identity") +
  labs(title = "Distribution of Pollution Levels",
       x = "Pollution Level", y = "Count") +
  theme_classic()

```




\newpage
3.3: EV Density vs Pollution
```{r, warning=FALSE, message=FALSE}
ggplot(model_data, aes(x = EV_Station_Density, y = Data_Value, color = BOROUGH)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "EV Station Density vs Air Pollution",
       x = "EV Station Density", y = "Pollution Level") +
  theme_minimal()

```





\newpage
Step 4: Correlation Matrix
```{r, warning=FALSE, message=FALSE}
```




\newpage
Step 5: Fixed Effects Model 
```{r, warning=FALSE, message=FALSE}
model_data <- model_data %>%
  group_by(BOROUGH, Geo.Place.Name, Name) %>%
  mutate(row_num = row_number(),
         Panel_ID = paste(BOROUGH, Geo.Place.Name, Name, row_num, sep = "_")) %>%
  ungroup()

panel_data <- pdata.frame(model_data, index = c("Panel_ID", "Year"))
table(duplicated(model_data[c("Panel_ID", "Year")]))  # Should be all FALSE now

panel_data <- pdata.frame(model_data, index = c("BOROUGH", "Year"))

fe_model <- plm(
  Data_Value ~ EV_Station_Density + Public_Pct + Time_Since_EV_Adoption,
  data = panel_data,
  model = "within"
)


# Summarize the model
summary(fe_model)

library(lmtest)
library(sandwich)

coeftest(fe_model, vcov = vcovHC(fe_model, type = "HC1"))

```

4. Instrumental Variables Approach
```{r}
# Load required package
if (!require(lfe)) install.packages("lfe")
library(lfe)
# Proper IV specification:
iv_model <- lfe::felm(Data_Value ~ 1 |                    # No covariates
                     factor(BOROUGH) + factor(Year) |     # Fixed effects 
                     (EV_Station_Density ~ I(Year >= 2018)),  # IV formula
                   data = model_data)

# Alternative with controls:
iv_model_controlled <- lfe::felm(
  Data_Value ~ Stations + Public_Pct |          # Controls
  factor(BOROUGH) + factor(Year) |             # Fixed effects
  (EV_Station_Density ~ I(Year >= 2018)),      # IV formula
  data = model_data
)

# View results
summary(iv_model, robust = TRUE)  # Cluster-robust SEs
summary(iv_model_controlled, robust = TRUE)
```


\newpage
Step 6: Save Results
```{r, warning=FALSE, message=FALSE}
# Save descriptive stats
write.csv(desc_stats, "Descriptive_Stats.csv")

# Save plots
ggsave("Profile_Plot.png", width = 8, height = 5)
ggsave("EV_vs_Pollution.png", width = 8, height = 5)

```


\newpage
Time-Series Analysis
```{r}
# Aggregate by Year (NYC overall)
nyc_pollution_ts <- model_data %>%
  group_by(Year) %>%
  summarise(Pollution = mean(Data_Value, na.rm = TRUE))

ts_data <- ts(nyc_pollution_ts$Pollution, start = min(nyc_pollution_ts$Year))

# Fit ARIMA model
library(forecast)
auto_model <- auto.arima(ts_data)
summary(auto_model)

# Forecast 3 years ahead
forecasted <- forecast(auto_model, h = 3)

```


```{r, warning=FALSE, message=FALSE}
autoplot(forecasted) +
  labs(title = "Forecasted Pollution Levels", y = "Pollution") +
  theme_minimal()

```

Simple Trend Plot (Profile Plot)
```{r, warning=FALSE, message=FALSE}
nyc_profile_plot <- ggplot(nyc_pollution_ts, aes(x = Year, y = Pollution)) +
  geom_line(color = "#1f77b4", size = 1.2) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed", color = "#ff7f0e") +
  labs(title = "Profile Plot: Annual Average Pollution Levels in NYC",
       y = "Pollutant Value",
       x = "Year") +
  theme_minimal()

ggsave("Profile_Plot_NYC.png", nyc_profile_plot, width = 8, height = 5)
```


5. Robustness Checks
```{r}
# Placebo test - pretend treatment was in 2016
model_data <- model_data %>%
  mutate(
    Placebo_Post = ifelse(Year >= 2016, 1, 0),
    Placebo_DiD = Treatment * Placebo_Post
  )

placebo_model <- felm(Data_Value ~ Treatment + Placebo_Post + Placebo_DiD | BOROUGH + Year, 
                     data = model_data)
summary(placebo_model) # Should show no effect

# Exclude COVID years
no_covid_data <- model_data %>% filter(!Year %in% 2020:2021)
did_model_no_covid <- felm(Data_Value ~ Treatment + Post + DiD | BOROUGH + Year, 
                          data = no_covid_data)
summary(did_model_no_covid)

# Save all results
results_list <- list(
  Granger_Test = summary(granger_test),
  DiD_Model = summary(did_model_robust),
  IV_Model = summary(iv_model),
  Placebo_Test = summary(placebo_model),
  No_COVID_DiD = summary(did_model_no_covid)
)

capture.output(results_list, file = "Causal_Inference_Results.txt")
```


\newpage
Multilevel Modeling
```{r, warning=FALSE, message=FALSE}
# Multilevel Modeling with Diagnostics

library(lme4)
library(car)

# 1. Check multicollinearity
lm_model <- lm(Data_Value ~ EV_Station_Density + Public_Pct + Time_Since_EV_Adoption, data = model_data)
vif(lm_model)

# 2. Fit mixed-effects model with random slope for Time_Since_EV_Adoption
mixed_model <- lmer(Data_Value ~ EV_Station_Density + Public_Pct + Time_Since_EV_Adoption +
                      (Time_Since_EV_Adoption | Geo.Place.Name), data = model_data)
summary(mixed_model)

# 3. Model diagnostics

# Q-Q plot for normality of residuals
qqnorm(resid(mixed_model))
qqline(resid(mixed_model))

# Residual vs fitted plot
plot(mixed_model)

```


\newpage
Causal Inference (DiD)
```{r, warning=FALSE, message=FALSE}
# Define treatment group: top 25% EV density
quantile_cutoff <- quantile(model_data$EV_Station_Density, 0.75, na.rm = TRUE)

model_data <- model_data %>%
  mutate(Treatment = ifelse(EV_Station_Density >= quantile_cutoff, 1, 0),
         Post = ifelse(Year >= 2014, 1, 0),
         DiD = Treatment * Post)

# Run DiD regression
did_model <- lm(Data_Value ~ Treatment + Post + DiD + factor(BOROUGH) + factor(Year), data = model_data)
summary(did_model)


```


 DiD Visualization: Pollution Trends by Treatment Group
```{r, warning=FALSE, message=FALSE}
model_data %>%
  group_by(Year, Treatment) %>%
  summarise(Pollution = mean(Data_Value, na.rm = TRUE)) %>%
  ggplot(aes(x = Year, y = Pollution, color = as.factor(Treatment), linetype = as.factor(Treatment))) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  labs(title = "Trends in Pollution by Treatment Group (Pre vs Post)",
       x = "Year", y = "Average Pollution",
       color = "Treatment Group", linetype = "Treatment Group") +
  scale_color_manual(values = c("0" = "gray40", "1" = "steelblue"),
                     labels = c("Control", "Treated")) +
  scale_linetype_manual(values = c("0" = "dashed", "1" = "solid"),
                        labels = c("Control", "Treated")) +
  theme_minimal()

```


2. Strengthened DiD Analysis (2014-2024)
```{r}
# Define treatment groups more rigorously
model_data <- model_data %>%
  group_by(BOROUGH) %>%
  mutate(
    # Corrected median calculation with proper parentheses
    Treatment = ifelse(Year >= 2018 & 
                       EV_Station_Density > median(EV_Station_Density[Year >= 2018], na.rm = TRUE), 
                     1, 0),
    # Ensure no treatment before 2018
    Treatment = ifelse(Year < 2018, 0, Treatment),
    Post = ifelse(Year >= 2018, 1, 0),
    DiD = Treatment * Post
  ) %>%
  ungroup()

# Check treatment assignment
table(model_data$Treatment, model_data$BOROUGH, model_data$Year)

# Improved DiD model with borough and year fixed effects
did_model_robust <- lfe::felm(Data_Value ~ Treatment + Post + DiD | BOROUGH + Year, 
                             data = model_data)
summary(did_model_robust)

# Visualize parallel trends with error handling
parallel_trends <- model_data %>%
  group_by(Year, Treatment) %>%
  summarise(
    Mean_Pollution = mean(Data_Value, na.rm = TRUE),
    SE = sd(Data_Value, na.rm = TRUE)/sqrt(n()),
    .groups = 'drop'
  )

ggplot(parallel_trends, aes(x = Year, y = Mean_Pollution, 
                          color = factor(Treatment), 
                          linetype = factor(Treatment))) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = Mean_Pollution - 1.96*SE,
                  ymax = Mean_Pollution + 1.96*SE,
                  fill = factor(Treatment)),
              alpha = 0.2) +
  geom_vline(xintercept = 2018, linetype = "dashed", color = "red") +
  labs(title = "Parallel Trends Assumption Check (2014-2024)",
       subtitle = "Dashed line marks policy implementation year (2018)",
       x = "Year",
       y = "Mean Pollution Level (ppb)",
       color = "Treatment Group",
       linetype = "Treatment Group",
       fill = "Treatment Group") +
  scale_color_manual(values = c("0" = "#E69F00", "1" = "#0072B2")) +
  scale_fill_manual(values = c("0" = "#E69F00", "1" = "#0072B2")) +
  theme_minimal(base_size = 12) +
  theme(legend.position = "bottom")

# Cluster standard errors at borough level
did_model_clustered <- lfe::felm(Data_Value ~ Treatment + Post + DiD | BOROUGH + Year, 
                               data = model_data)
summary(did_model_clustered, robust = TRUE)
```

```{r}
### --------------------------
### 3. Synthetic Control Method
### --------------------------

# For boroughs with highest EV growth (e.g., Manhattan)
manhattan_data <- model_data %>%
  filter(BOROUGH == "MANHATTAN") %>%
  select(Year, Data_Value, EV_Station_Density, Stations) %>%
  distinct()

control_boroughs <- model_data %>%
  filter(BOROUGH != "MANHATTAN") %>%
  select(BOROUGH, Year, Data_Value) %>%
  pivot_wider(names_from = BOROUGH, values_from = Data_Value)

# Prep data for synth package
synth_data <- dataprep(
  foo = control_boroughs,
  predictors = c("BRONX", "BROOKLYN", "QUEENS", "STATEN ISLAND"),
  dependent = "BRONX", # Just using one as example
  unit.variable = "BOROUGH",
  time.variable = "Year",
  treatment.identifier = "MANHATTAN",
  controls.identifier = c("BRONX", "BROOKLYN", "QUEENS", "STATEN ISLAND"),
  time.predictors.prior = 2014:2017,
  time.optimize.ssr = 2014:2017,
  time.plot = 2014:2024
)

# Run synthetic control
synth_out <- synth(synth_data)
path.plot(synth_out, synth_data)
```

\newpage
Geospatial Analysis: EV Station Growth in NYC (2020–2024)

```{r, warning=FALSE, message=FALSE}
# Load necessary packages
library(readr)
library(dplyr)
library(stringr)
library(lubridate)
library(ggplot2)
library(sf)
library(leaflet)
library(viridis)

# Step 1: Load and clean EV station data
ev_geo_data <- read_csv("EV_CS_NYC.csv") %>%
  mutate(
    Open_Date = mdy(`Open Date`),
    Open_Year = year(Open_Date),
    City = str_to_upper(str_trim(City)),
    BOROUGH = case_when(
      City %in% c("NEW YORK", "MANHATTAN") ~ "MANHATTAN",
      City == "BROOKLYN" ~ "BROOKLYN",
      City == "BRONX" ~ "BRONX",
      City == "QUEENS" ~ "QUEENS",
      City == "STATEN ISLAND" ~ "STATEN ISLAND",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(Open_Year >= 2014 & Open_Year <= 2024, !is.na(BOROUGH)) %>%
  select(Station_Name = `Station Name`, Open_Date, Open_Year, BOROUGH, Latitude, Longitude,
         `EV Level2 EVSE Num`, `EV DC Fast Count`, `Groups With Access Code`)

# Save for external use (optional)
write_csv(ev_geo_data, "EV_Station_Data_with_Geolocation.csv")

```


Basic Static Plot: EV Station Locations by Borough
```{r, warning=FALSE, message=FALSE}
ggplot(ev_geo_data, aes(x = Longitude, y = Latitude, color = BOROUGH)) +
  geom_point(alpha = 0.6, size = 2) +
  labs(title = "EV Charging Stations in NYC (2020–2024)",
       subtitle = "Color-coded by Borough") +
  theme_minimal() +
  coord_fixed()

```


Facet by Year: Visualize Station Growth
```{r, warning=FALSE, message=FALSE}
ggplot(ev_geo_data, aes(x = Longitude, y = Latitude, color = BOROUGH)) +
  geom_point(alpha = 0.5, size = 1.5) +
  facet_wrap(~ Open_Year) +
  labs(title = "EV Charging Station Expansion by Year",
       x = "Longitude", y = "Latitude") +
  theme_minimal() +
  coord_fixed()

```



Add Borough Boundaries
```{r, warning=FALSE, message=FALSE}
# Load NYC borough shapefile or GeoJSON — change path to your file
nyc_boroughs <- st_read("Borough Boundaries_20250417.geojson") 

ggplot() +
  geom_sf(data = nyc_boroughs, fill = "gray95", color = "black") +
  geom_point(data = ev_geo_data, aes(x = Longitude, y = Latitude, color = BOROUGH), size = 1.5, alpha = 0.6) +
  labs(title = "EV Charging Stations in NYC with Borough Boundaries",
       x = "Longitude", y = "Latitude") +
  theme_minimal() +
  coord_sf()

```


Interactive Map
```{r, warning=FALSE, message=FALSE}
leaflet_map <-leaflet(ev_geo_data) %>%
  addProviderTiles("CartoDB.Positron") %>%
  addCircleMarkers(
    ~Longitude, ~Latitude,
    color = ~case_when(
      BOROUGH == "MANHATTAN" ~ "blue",
      BOROUGH == "BROOKLYN" ~ "green",
      BOROUGH == "QUEENS" ~ "orange",
      BOROUGH == "BRONX" ~ "red",
      BOROUGH == "STATEN ISLAND" ~ "purple",
      TRUE ~ "gray"
    ),
    radius = 4, stroke = FALSE, fillOpacity = 0.7,
    popup = ~paste0("<b>Station:</b> ", Station_Name,
                    "<br><b>Borough:</b> ", BOROUGH,
                    "<br><b>Year:</b> ", Open_Year)
  ) %>%
  addLegend("bottomright", 
            colors = c("blue", "green", "orange", "red", "purple"),
            labels = c("Manhattan", "Brooklyn", "Queens", "Bronx", "Staten Island"),
            title = "NYC Boroughs")
leaflet_map
```


```{r, warning=FALSE, message=FALSE}
library(htmlwidgets)
library(webshot2)

# Save the leaflet map as an HTML file
saveWidget(leaflet_map, "EV_Stations_Map.html", selfcontained = TRUE)

# Convert that HTML file to a PNG (requires webshot2 and Chrome)
webshot("EV_Stations_Map.html", file = "EV_Stations_Map.png", vwidth = 1200, vheight = 800)

```



```{r}

```



